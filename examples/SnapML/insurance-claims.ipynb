{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2019, 2020. IBM All Rights Reserved.\n",
    "```\n",
    "\n",
    "```\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allstate Claim Prediction Challenge using Snap ML\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Snap ML</b> is packaged with <b>IBM® Watson™ Machine Learning Community Edition (WML CE)</b> in a conda package <b>pai4sk</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allstate Claim Prediction\n",
    "This example is based on a competition in Kaggle - https://www.kaggle.com/c/ClaimPredictionChallenge\n",
    "In this notebook we will train a <b>Logistic Regression</b> model to predict if a customer would claim a bodily injury liability insurance based on the characteristics of the insured customer's vehicle.<br/>\n",
    "We will train the models using <b>scikit-learn</b> and <b>SnapML</b>, and compare the results.\n",
    "\n",
    "### Data source\n",
    "Dataset used for this notebook is downloaded from https://www.kaggle.com/c/ClaimPredictionChallenge/data with all rights reserved by Kaggle and Allstate Corporation. Here we have used Kaggle API (https://github.com/Kaggle/kaggle-api) to download the dataset.\n",
    "\n",
    "### Conda packages used for this notebook \n",
    "- `pai4sk       1.6.0   (Package for IBM Snap ML, provided in WML CE 1.7.0)`\n",
    "- `scikit-learn 0.22.1  (Package for sklearn)`\n",
    "- `pandas       1.0.0   (Package for pandas)`\n",
    "- `kaggle       1.5.6   (Package for using Kaggle APIs)`\n",
    "- `matplotlib   3.1.3   (Package for matplotlib)`\n",
    "\n",
    "### System Configuration \n",
    "\n",
    "|Configuration Parameter |\tValue                         |\n",
    "|:-----------------------|:-------------------------------|       \n",
    "| **Machine** \t         | IBM Power9 AC922               |\n",
    "| **CPU cores:**         | 44 (22 cores per socket)       |\n",
    "| **Thread(s) per core:**| 4                              |\n",
    "| **GPU** \t             | NVIDIA Tesla V100 SXM2 16GB    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Download the dataset using kaggle APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download ClaimPredictionChallenge\n",
    "!unzip ClaimPredictionChallenge.zip\n",
    "!unzip train_set.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Load the data into pandas dataframe and view descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Row_ID</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Household_ID</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vehicle</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calendar_Year</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2006</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Year</th>\n",
       "      <td>2005</td>\n",
       "      <td>2003</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blind_Make</th>\n",
       "      <td>K</td>\n",
       "      <td>Q</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blind_Model</th>\n",
       "      <td>K.78</td>\n",
       "      <td>Q.22</td>\n",
       "      <td>AR.41</td>\n",
       "      <td>AR.41</td>\n",
       "      <td>D.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blind_Submodel</th>\n",
       "      <td>K.78.2</td>\n",
       "      <td>Q.22.3</td>\n",
       "      <td>AR.41.1</td>\n",
       "      <td>AR.41.1</td>\n",
       "      <td>D.20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat1</th>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat2</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat3</th>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat4</th>\n",
       "      <td>?</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat5</th>\n",
       "      <td>?</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat6</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat7</th>\n",
       "      <td>?</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat8</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat9</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat10</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat11</th>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat12</th>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdCat</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var1</th>\n",
       "      <td>1.27053</td>\n",
       "      <td>0.217951</td>\n",
       "      <td>-0.754282</td>\n",
       "      <td>-0.754282</td>\n",
       "      <td>0.563454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var2</th>\n",
       "      <td>0.999418</td>\n",
       "      <td>0.56714</td>\n",
       "      <td>-1.64613</td>\n",
       "      <td>-1.64613</td>\n",
       "      <td>1.86398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var3</th>\n",
       "      <td>0.588154</td>\n",
       "      <td>1.42121</td>\n",
       "      <td>-1.10109</td>\n",
       "      <td>-1.10109</td>\n",
       "      <td>1.81459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var4</th>\n",
       "      <td>0.908351</td>\n",
       "      <td>0.485509</td>\n",
       "      <td>-1.67944</td>\n",
       "      <td>-1.67944</td>\n",
       "      <td>1.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var5</th>\n",
       "      <td>1.00891</td>\n",
       "      <td>1.24085</td>\n",
       "      <td>-0.971487</td>\n",
       "      <td>-0.971487</td>\n",
       "      <td>0.812656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var6</th>\n",
       "      <td>0.26104</td>\n",
       "      <td>0.432987</td>\n",
       "      <td>-1.4058</td>\n",
       "      <td>-1.4058</td>\n",
       "      <td>2.11269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var7</th>\n",
       "      <td>0.907793</td>\n",
       "      <td>-0.726459</td>\n",
       "      <td>-0.837048</td>\n",
       "      <td>-0.837048</td>\n",
       "      <td>1.53446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var8</th>\n",
       "      <td>-0.077998</td>\n",
       "      <td>0.204785</td>\n",
       "      <td>-1.17686</td>\n",
       "      <td>-1.17686</td>\n",
       "      <td>2.34726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVCat</th>\n",
       "      <td>M</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVVar1</th>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.23153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVVar2</th>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.266117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVVar3</th>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.272337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVVar4</th>\n",
       "      <td>-0.251419</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>-0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim_Amount</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3         4\n",
       "Row_ID                 1         2         3         4         5\n",
       "Household_ID           1         2         3         3         3\n",
       "Vehicle                3         2         1         1         2\n",
       "Calendar_Year       2005      2005      2005      2006      2005\n",
       "Model_Year          2005      2003      1998      1998      2001\n",
       "Blind_Make             K         Q        AR        AR         D\n",
       "Blind_Model         K.78      Q.22     AR.41     AR.41      D.20\n",
       "Blind_Submodel    K.78.2    Q.22.3   AR.41.1   AR.41.1    D.20.0\n",
       "Cat1                   D         B         B         B         J\n",
       "Cat2                   C         C         ?         ?         C\n",
       "Cat3                   F         A         A         A         B\n",
       "Cat4                   ?         A         A         A         ?\n",
       "Cat5                   ?         A         A         A         ?\n",
       "Cat6                   C         E         C         C         D\n",
       "Cat7                   ?         C         C         C         ?\n",
       "Cat8                   C         A         A         A         A\n",
       "Cat9                   A         B         B         B         B\n",
       "Cat10                  B         A         A         B         A\n",
       "Cat11                  F         B         E         B         B\n",
       "Cat12                  D         D         D         B         B\n",
       "OrdCat                 4         5         2         2         5\n",
       "Var1             1.27053  0.217951 -0.754282 -0.754282  0.563454\n",
       "Var2            0.999418   0.56714  -1.64613  -1.64613   1.86398\n",
       "Var3            0.588154   1.42121  -1.10109  -1.10109   1.81459\n",
       "Var4            0.908351  0.485509  -1.67944  -1.67944    1.8386\n",
       "Var5             1.00891   1.24085 -0.971487 -0.971487  0.812656\n",
       "Var6             0.26104  0.432987   -1.4058   -1.4058   2.11269\n",
       "Var7            0.907793 -0.726459 -0.837048 -0.837048   1.53446\n",
       "Var8           -0.077998  0.204785  -1.17686  -1.17686   2.34726\n",
       "NVCat                  M         O         F         F         F\n",
       "NVVar1          -0.23153  -0.23153  -0.23153  -0.23153  -0.23153\n",
       "NVVar2         -0.266117 -0.266117 -0.266117 -0.266117 -0.266117\n",
       "NVVar3         -0.272337 -0.272337 -0.272337 -0.272337 -0.272337\n",
       "NVVar4         -0.251419 -0.251419 -0.251419 -0.251419 -0.251419\n",
       "Claim_Amount           0         0         0         0         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 13184290 observations and 35 features\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset has \" + str(df.shape[0]) + \" observations and \" + str(df.shape[1]) + \" features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_ID</th>\n",
       "      <th>Household_ID</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Calendar_Year</th>\n",
       "      <th>Model_Year</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>NVVar1</th>\n",
       "      <th>NVVar2</th>\n",
       "      <th>NVVar3</th>\n",
       "      <th>NVVar4</th>\n",
       "      <th>Claim_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>1.318429e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.592146e+06</td>\n",
       "      <td>4.128242e+06</td>\n",
       "      <td>1.894002e+00</td>\n",
       "      <td>2.006052e+03</td>\n",
       "      <td>1.999312e+03</td>\n",
       "      <td>-1.011925e-02</td>\n",
       "      <td>-6.508702e-02</td>\n",
       "      <td>-2.543391e-02</td>\n",
       "      <td>-5.456792e-02</td>\n",
       "      <td>3.838594e-03</td>\n",
       "      <td>-4.012271e-02</td>\n",
       "      <td>-2.421288e-02</td>\n",
       "      <td>-5.856059e-02</td>\n",
       "      <td>1.468410e-02</td>\n",
       "      <td>1.751169e-02</td>\n",
       "      <td>1.354226e-02</td>\n",
       "      <td>1.851376e-02</td>\n",
       "      <td>1.360658e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.805977e+06</td>\n",
       "      <td>2.248415e+06</td>\n",
       "      <td>1.173861e+00</td>\n",
       "      <td>8.123720e-01</td>\n",
       "      <td>5.211866e+00</td>\n",
       "      <td>9.800609e-01</td>\n",
       "      <td>9.684165e-01</td>\n",
       "      <td>1.018902e+00</td>\n",
       "      <td>9.680170e-01</td>\n",
       "      <td>9.910490e-01</td>\n",
       "      <td>9.792078e-01</td>\n",
       "      <td>1.006433e+00</td>\n",
       "      <td>1.003954e+00</td>\n",
       "      <td>1.031040e+00</td>\n",
       "      <td>1.038212e+00</td>\n",
       "      <td>1.027748e+00</td>\n",
       "      <td>1.034274e+00</td>\n",
       "      <td>3.900103e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.005000e+03</td>\n",
       "      <td>1.981000e+03</td>\n",
       "      <td>-2.578222e+00</td>\n",
       "      <td>-2.493393e+00</td>\n",
       "      <td>-2.790335e+00</td>\n",
       "      <td>-2.508216e+00</td>\n",
       "      <td>-3.350344e+00</td>\n",
       "      <td>-2.376657e+00</td>\n",
       "      <td>-2.778490e+00</td>\n",
       "      <td>-2.163042e+00</td>\n",
       "      <td>-2.315299e-01</td>\n",
       "      <td>-2.661168e-01</td>\n",
       "      <td>-2.723372e-01</td>\n",
       "      <td>-2.514189e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.296073e+06</td>\n",
       "      <td>2.184932e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.005000e+03</td>\n",
       "      <td>1.996000e+03</td>\n",
       "      <td>-6.658971e-01</td>\n",
       "      <td>-8.161519e-01</td>\n",
       "      <td>-8.696874e-01</td>\n",
       "      <td>-7.830189e-01</td>\n",
       "      <td>-6.860239e-01</td>\n",
       "      <td>-6.887650e-01</td>\n",
       "      <td>-8.984857e-01</td>\n",
       "      <td>-6.517680e-01</td>\n",
       "      <td>-2.315299e-01</td>\n",
       "      <td>-2.661168e-01</td>\n",
       "      <td>-2.723372e-01</td>\n",
       "      <td>-2.514189e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.592146e+06</td>\n",
       "      <td>4.257083e+06</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.006000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>-3.123581e-01</td>\n",
       "      <td>-1.245062e-01</td>\n",
       "      <td>-2.217581e-01</td>\n",
       "      <td>-1.064709e-01</td>\n",
       "      <td>-1.150981e-01</td>\n",
       "      <td>-2.372568e-01</td>\n",
       "      <td>-4.684193e-01</td>\n",
       "      <td>-2.568567e-01</td>\n",
       "      <td>-2.315299e-01</td>\n",
       "      <td>-2.661168e-01</td>\n",
       "      <td>-2.723372e-01</td>\n",
       "      <td>-2.514189e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.888218e+06</td>\n",
       "      <td>6.281433e+06</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.007000e+03</td>\n",
       "      <td>2.003000e+03</td>\n",
       "      <td>4.429298e-01</td>\n",
       "      <td>4.806838e-01</td>\n",
       "      <td>7.269956e-01</td>\n",
       "      <td>4.855086e-01</td>\n",
       "      <td>5.331405e-01</td>\n",
       "      <td>4.973212e-01</td>\n",
       "      <td>8.217801e-01</td>\n",
       "      <td>3.409799e-01</td>\n",
       "      <td>-2.315299e-01</td>\n",
       "      <td>-2.661168e-01</td>\n",
       "      <td>-2.723372e-01</td>\n",
       "      <td>-2.514189e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.318429e+07</td>\n",
       "      <td>7.542113e+06</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>2.007000e+03</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>5.143392e+00</td>\n",
       "      <td>7.829420e+00</td>\n",
       "      <td>5.563325e+00</td>\n",
       "      <td>7.589263e+00</td>\n",
       "      <td>4.018167e+00</td>\n",
       "      <td>4.584289e+00</td>\n",
       "      <td>4.127148e+00</td>\n",
       "      <td>4.735074e+01</td>\n",
       "      <td>6.627110e+00</td>\n",
       "      <td>8.883081e+00</td>\n",
       "      <td>8.691144e+00</td>\n",
       "      <td>6.388802e+00</td>\n",
       "      <td>1.144075e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Row_ID  Household_ID       Vehicle  Calendar_Year    Model_Year  \\\n",
       "count  1.318429e+07  1.318429e+07  1.318429e+07   1.318429e+07  1.318429e+07   \n",
       "mean   6.592146e+06  4.128242e+06  1.894002e+00   2.006052e+03  1.999312e+03   \n",
       "std    3.805977e+06  2.248415e+06  1.173861e+00   8.123720e-01  5.211866e+00   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00   2.005000e+03  1.981000e+03   \n",
       "25%    3.296073e+06  2.184932e+06  1.000000e+00   2.005000e+03  1.996000e+03   \n",
       "50%    6.592146e+06  4.257083e+06  2.000000e+00   2.006000e+03  2.000000e+03   \n",
       "75%    9.888218e+06  6.281433e+06  2.000000e+00   2.007000e+03  2.003000e+03   \n",
       "max    1.318429e+07  7.542113e+06  2.900000e+01   2.007000e+03  2.009000e+03   \n",
       "\n",
       "               Var1          Var2          Var3          Var4          Var5  \\\n",
       "count  1.318429e+07  1.318429e+07  1.318429e+07  1.318429e+07  1.318429e+07   \n",
       "mean  -1.011925e-02 -6.508702e-02 -2.543391e-02 -5.456792e-02  3.838594e-03   \n",
       "std    9.800609e-01  9.684165e-01  1.018902e+00  9.680170e-01  9.910490e-01   \n",
       "min   -2.578222e+00 -2.493393e+00 -2.790335e+00 -2.508216e+00 -3.350344e+00   \n",
       "25%   -6.658971e-01 -8.161519e-01 -8.696874e-01 -7.830189e-01 -6.860239e-01   \n",
       "50%   -3.123581e-01 -1.245062e-01 -2.217581e-01 -1.064709e-01 -1.150981e-01   \n",
       "75%    4.429298e-01  4.806838e-01  7.269956e-01  4.855086e-01  5.331405e-01   \n",
       "max    5.143392e+00  7.829420e+00  5.563325e+00  7.589263e+00  4.018167e+00   \n",
       "\n",
       "               Var6          Var7          Var8        NVVar1        NVVar2  \\\n",
       "count  1.318429e+07  1.318429e+07  1.318429e+07  1.318429e+07  1.318429e+07   \n",
       "mean  -4.012271e-02 -2.421288e-02 -5.856059e-02  1.468410e-02  1.751169e-02   \n",
       "std    9.792078e-01  1.006433e+00  1.003954e+00  1.031040e+00  1.038212e+00   \n",
       "min   -2.376657e+00 -2.778490e+00 -2.163042e+00 -2.315299e-01 -2.661168e-01   \n",
       "25%   -6.887650e-01 -8.984857e-01 -6.517680e-01 -2.315299e-01 -2.661168e-01   \n",
       "50%   -2.372568e-01 -4.684193e-01 -2.568567e-01 -2.315299e-01 -2.661168e-01   \n",
       "75%    4.973212e-01  8.217801e-01  3.409799e-01 -2.315299e-01 -2.661168e-01   \n",
       "max    4.584289e+00  4.127148e+00  4.735074e+01  6.627110e+00  8.883081e+00   \n",
       "\n",
       "             NVVar3        NVVar4  Claim_Amount  \n",
       "count  1.318429e+07  1.318429e+07  1.318429e+07  \n",
       "mean   1.354226e-02  1.851376e-02  1.360658e+00  \n",
       "std    1.027748e+00  1.034274e+00  3.900103e+01  \n",
       "min   -2.723372e-01 -2.514189e-01  0.000000e+00  \n",
       "25%   -2.723372e-01 -2.514189e-01  0.000000e+00  \n",
       "50%   -2.723372e-01 -2.514189e-01  0.000000e+00  \n",
       "75%   -2.723372e-01 -2.514189e-01  0.000000e+00  \n",
       "max    8.691144e+00  6.388802e+00  1.144075e+04  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Visualize claims distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = 'Claimed', 'Not-claimed'\n",
    "sizes = [len(df[df.Claim_Amount>0]), len(df[df.Claim_Amount==0])]\n",
    "explode = (0.1, 0)\n",
    "colors = ['r','c']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', colors=colors)\n",
    "ax.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    The percentage of customers that claimed insurance is only <b>0.7</b> of the total insured vehicles. We will use the <b>class_weight</b> parameter of the frameworks for training to create a balanced model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Clean the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Drop columns we don't want to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Row_ID column\n",
    "df.drop(['Row_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Replace all missing values with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values are coded as '?'\n",
    "df.replace('?', np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with -1\n",
    "df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the target variable 'Claim Amount', and drop that from the train\n",
    "df_Y = df[['Claim_Amount']]\n",
    "df_X = df.drop(['Claim_Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape =  (9229003, 33)\n",
      "X_test.shape =  (3955287, 33)\n"
     ]
    }
   ],
   "source": [
    "# Split out 30% of the observations for test \n",
    "X_train, X_test, y_train, y_test  = train_test_split (df_X, df_Y, test_size=0.3, random_state=42)\n",
    "print('X_train.shape = ', X_train.shape)\n",
    "print('X_test.shape = ',  X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index after split for concat operations\n",
    "X_train.reset_index(inplace=True)\n",
    "X_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Label encoding for some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Blind_Make', 'Blind_Model', 'Blind_Submodel', 'NVCat']:\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # fit label encoder\n",
    "    le.fit(X_train[col])\n",
    "\n",
    "    # extract dictionary mapping from label encoder\n",
    "    le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "    # replace categories with labels (assign label -1 if not in dict)\n",
    "    X_train[col] = X_train[col].map(lambda x: le_dict.get(x, -1))\n",
    "    X_test[col] = X_test[col].map(lambda x: le_dict.get(x, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One-hot encoding for the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5', 'Cat6', 'Cat7', 'Cat8', 'Cat9', 'Cat10', 'Cat11', 'Cat12']\n",
    "for col in categoricalColumns:\n",
    "\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "    oh = OneHotEncoder(handle_unknown='ignore')\n",
    "    tmp_train = oh.fit_transform(X_train[col].values.reshape(-1,1)).toarray()\n",
    "    tmp_test = oh.transform(X_test[col].values.reshape(-1,1)).toarray()\n",
    "\n",
    "    assert(tmp_train.shape[1] == tmp_test.shape[1])\n",
    "\n",
    "    X_train = X_train.drop(col,axis=1)\n",
    "    X_test = X_test.drop(col,axis=1)\n",
    "\n",
    "    new_cols = [col + '-' + str(int(i)) for i in range(tmp_train.shape[1])]\n",
    "\n",
    "    tmp_train = pd.DataFrame(tmp_train, columns=new_cols)\n",
    "    tmp_test  = pd.DataFrame(tmp_test,  columns=new_cols)\n",
    "\n",
    "    X_train = pd.concat([X_train, tmp_train],axis=1)\n",
    "    X_test  = pd.concat([X_test,  tmp_test],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Derive Vehicle Age and use it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Calendar_Year']:\n",
    "    X_train['Vehicle_Age'] = X_train['Calendar_Year'] - X_train['Model_Year']\n",
    "    X_test['Vehicle_Age'] = X_test['Calendar_Year'] - X_test['Model_Year']\n",
    "\n",
    "X_train.drop(['Calendar_Year'], axis=1, inplace=True)\n",
    "X_test.drop(['Calendar_Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Features scaling and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(X_train)\n",
    "X_train = min_max_scaler.transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and cast array to float32\n",
    "X_train = normalize(X_train, axis=1, norm='l1').astype('float32')\n",
    "X_test = normalize(X_test, axis=1, norm='l1').astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Convert labels for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test also to numpy arrays of float32\n",
    "y_train = y_train.values.astype(np.float32).ravel()\n",
    "y_test = y_test.values.astype(np.float32).ravel()\n",
    "\n",
    "# Create a binary classification problem (will there be an insurance claim or not)\n",
    "y_train = (y_train > 0).astype(int)\n",
    "y_test = (y_test > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. Use Optimized data formats for each framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Compute the sparsity of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is 65.718776 percent sparse \n"
     ]
    }
   ],
   "source": [
    "from numpy import count_nonzero\n",
    "sparsity = 1.0 - (count_nonzero(X_train) / float(X_train.shape[0]*X_train.shape[1]) )\n",
    "print(\"The train dataset is %f percent sparse \" % (sparsity*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Since this dataset is reasonably sparse, convert it to scipy sparse csr_matrix\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Snap ML employs optimizations for the algorithms when applied to sparse data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both sklearn and snap ML provide support for sparse datasets for linear models\n",
    "from scipy import sparse\n",
    "X_train_sparse = sparse.csr_matrix(X_train)\n",
    "X_test_sparse = sparse.csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Regularizer value used across frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Train using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn-logreg] Training time (s): 222.380\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "skl_lor = LogisticRegression(C = 1.0/reg, class_weight='balanced')\n",
    "\n",
    "t0 = time.time()\n",
    "skl_lor.fit(X_train_sparse, y_train)\n",
    "skl_train_time_lor = time.time()-t0\n",
    "print(\"[sklearn-logreg] Training time (s): {0:.3f}\".format(skl_train_time_lor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evaluate gini score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn-logreg] gini_score 0.1250\n"
     ]
    }
   ],
   "source": [
    "skl_pred = skl_lor.predict(X_test_sparse)\n",
    "skl_gini  = 2.0*roc_auc_score(y_test, skl_pred)-1.0\n",
    "print('[sklearn-logreg] gini_score %.4f' % (skl_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J. Train using SnapML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Train using \"<font color='red'>CPU</font>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Training will run in multi-threaded mode on CPU.\n",
      "[snapML-logreg] Training time (s): 8.730\n"
     ]
    }
   ],
   "source": [
    "from pai4sk import LogisticRegression\n",
    "sml_cpu_lor = LogisticRegression(regularizer=reg, class_weight='balanced', num_threads=16)\n",
    "\n",
    "t0 = time.time()\n",
    "sml_cpu_lor.fit(X_train_sparse, y_train)\n",
    "sml_cpu_train_time_lor = time.time()-t0\n",
    "print(\"[snapML-logreg] Training time (s): {0:.3f}\".format(sml_cpu_train_time_lor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evaluate gini score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[snapML-logreg] gini_score 0.1248\n"
     ]
    }
   ],
   "source": [
    "sml_cpu_pred = sml_cpu_lor.predict(X_test_sparse)\n",
    "sml_cpu_gini  = 2.0*roc_auc_score(y_test, sml_cpu_pred)-1.0\n",
    "print('[snapML-logreg] gini_score %.4f' % (sml_cpu_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Train using \"<font color='red'>GPU</font>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] If set num_threads should be a multiple of 32. GPU training will run with num_threads=256.\n",
      "[Warning] Parameter device_ids not set. The training will run on GPU 0.\n",
      "[snapML-logreg] Training time (s): 3.235\n"
     ]
    }
   ],
   "source": [
    "from pai4sk import LogisticRegression\n",
    "sml_gpu_lor = LogisticRegression(regularizer=reg, class_weight='balanced', use_gpu=True)\n",
    "\n",
    "t0 = time.time()\n",
    "sml_gpu_lor.fit(X_train_sparse, y_train)\n",
    "sml_gpu_train_time_lor = time.time()-t0\n",
    "print(\"[snapML-logreg] Training time (s): {0:.3f}\".format(sml_gpu_train_time_lor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evaluate gini score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[snapML-logreg] gini_score 0.1259\n"
     ]
    }
   ],
   "source": [
    "sml_gpu_pred = sml_gpu_lor.predict(X_test_sparse)\n",
    "sml_gpu_gini  = 2.0*roc_auc_score(y_test, sml_gpu_pred)-1.0\n",
    "print('[snapML-logreg] gini_score %.4f' % (sml_gpu_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K. Speedup summary\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The following results were obtained on an IBM Power AC922 server with NVIDIA Tesla V100 SXM2 16GB GPUs as mentioned in <a href='#System-Configuration'>System Configuration</a>.\n",
    "<br/>Speedup times may vary based on the system architecture, load and software package versions used.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SnapML(CPU) vs Sklearn training time speedup (Logistic) : 25 X \n",
      "SnapML(GPU) vs Sklearn training time speedup (Logistic) : 68 X \n"
     ]
    }
   ],
   "source": [
    "print(\"SnapML(CPU) vs Sklearn training time speedup (Logistic) : %d X \" % (skl_train_time_lor/sml_cpu_train_time_lor))\n",
    "print(\"SnapML(GPU) vs Sklearn training time speedup (Logistic) : %d X \" % (skl_train_time_lor/sml_gpu_train_time_lor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
