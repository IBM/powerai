{% set name = "allennlp" %}
{% set version = "0.9.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - folder: {{ name }}
    url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
    sha256: f70a2d83146630bcc213ed64ff868e3fed8519480fb495dee14a8a5b19c2ff90
    patches:
      - 0001-rename-pytorch_transformers-to-just-transformers.patch
      - 0001-Skip-unit-tests-over-dependent-on-spaCy-version.patch
      - 0001-Relax-tolerance-of-some-unit-tests.patch
      - 0001-Skip-one-test-that-fails-upstream-on-some-platforms.patch
      - 0001-Avoid-calling-argmax-on-Bool-tensor.patch
      - 0001-Allow-user-to-specify-name-of-gcc-for-evalb-build.patch

build:
  entry_points:
    - allennlp=allennlp.run:run
  number: 0
  script: "{{ PYTHON }} -m pip install ./{{ name }} --no-deps -vv"
  skip: True  # [not linux or py<36]

requirements:
  build:
    - {{ compiler('c') }}
    - patch
  host:
    - python
    - pip
  run:
    - python
    - pytorch-base >=1.2.0
    - jsonnet >=0.10.0
    - overrides
    - nltk
    - spacy >=2.2.0,<2.3.0a0
    - numpy
    - tensorboardx >=1.2
    - boto3
    - flask >=1.0.2
    - flask-cors >=3.0.7
    - gevent >=1.3.6
    - requests >=2.18
    - tqdm >=4.19
    - editdistance
    - h5py
    - scikit-learn
    - scipy
    - pytz >=2017.3
    - unidecode
    - matplotlib >=2.2.3
    - numpydoc >=0.8.0
    - conllu ==1.3.1
    - parsimonious >=0.8.0
    - ftfy
    - sqlparse >=0.2.4
    - word2number >=1.1
    - pytorch-pretrained-bert >=0.6.0
    - transformers >=1.1.0
    - jsonpickle

test:
  commands:
    # Some tests fail due to over-long path names when run during conda build
    # (dataset_reader_test and class TestTrainerUtil), so omit those only
    # during build test.
    - python -m spacy download en_core_web_sm
    - LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8 allennlp test-install -k "not dataset_reader_test and not TestTrainerUtil"
  imports:
    - allennlp.commands
    - allennlp.common
    - allennlp.common.testing
    - allennlp.data
    - allennlp.data.dataset_readers
    - allennlp.data.dataset_readers.coreference_resolution
    - allennlp.data.dataset_readers.dataset_utils
    - allennlp.data.dataset_readers.reading_comprehension
    - allennlp.data.dataset_readers.semantic_parsing
    - allennlp.data.dataset_readers.semantic_parsing.wikitables
    - allennlp.data.fields
    - allennlp.data.iterators
    - allennlp.data.token_indexers
    - allennlp.data.tokenizers
    - allennlp.interpret
    - allennlp.interpret.attackers
    - allennlp.interpret.saliency_interpreters
    - allennlp.models
    - allennlp.models.coreference_resolution
    - allennlp.models.encoder_decoders
    - allennlp.models.reading_comprehension
    - allennlp.models.semantic_parsing
    - allennlp.models.semantic_parsing.atis
    - allennlp.models.semantic_parsing.nlvr
    - allennlp.models.semantic_parsing.quarel
    - allennlp.models.semantic_parsing.wikitables
    - allennlp.modules
    - allennlp.modules.attention
    - allennlp.modules.language_model_heads
    - allennlp.modules.matrix_attention
    - allennlp.modules.seq2seq_decoders
    - allennlp.modules.seq2seq_encoders
    - allennlp.modules.seq2vec_encoders
    - allennlp.modules.similarity_functions
    - allennlp.modules.span_extractors
    - allennlp.modules.text_field_embedders
    - allennlp.modules.token_embedders
    - allennlp.nn
    - allennlp.nn.regularizers
    - allennlp.predictors
    - allennlp.semparse
    - allennlp.semparse.common
    - allennlp.semparse.contexts
    - allennlp.semparse.domain_languages
    - allennlp.semparse.executors
    - allennlp.semparse.type_declarations
    - allennlp.semparse.worlds
    - allennlp.service
    - allennlp.service.predictors
    - allennlp.state_machines
    - allennlp.state_machines.states
    - allennlp.state_machines.trainers
    - allennlp.state_machines.transition_functions
    - allennlp.tools
    - allennlp.training
    - allennlp.training.callbacks
    - allennlp.training.learning_rate_schedulers
    - allennlp.training.metrics
    - allennlp.training.momentum_schedulers
  requires:
    - {{ compiler('c') }} # to build evalb during test
    - make                # to build evalb during test
    - flaky
    - pytest
    - pytorch-cpu >= 1.2.0
    - responses >=0.7

about:
  home: https://allennlp.org/
  license: Apache-2.0
  license_family: APACHE
  license_file: {{ name }}/LICENSE
  summary: An open-source NLP research library, built on PyTorch.
  description: |
    An Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art 
    deep learning models on a wide variety of linguistic tasks.
  doc_url: https://allenai.github.io/allennlp-docs/
  dev_url: https://github.com/allenai/allennlp
